{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34_kn-lNnWY9"
   },
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GMS99WbinWZD"
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import ktrain\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-1oRzg4nWZE"
   },
   "source": [
    "### Task 2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ueYiHTPgnWZE"
   },
   "outputs": [],
   "source": [
    "with open(\"./task_6-1/training_set_clean_only_text.txt\", 'r', encoding='utf-8') as file:\n",
    "    X1 = np.array([x for x in file.readlines()])\n",
    "\n",
    "with open(\"./task_6-1/training_set_clean_only_tags.txt\", 'r', encoding='utf-8') as file:\n",
    "    y1 = np.array([int(y) for y in file.readlines()])\n",
    "\n",
    "with open(\"./task_6-2/training_set_clean_only_text.txt\", 'r', encoding='utf-8') as file:\n",
    "    X2 = np.array([x for x in file.readlines()])\n",
    "\n",
    "with open(\"./task_6-2/training_set_clean_only_tags.txt\", 'r', encoding='utf-8') as file:\n",
    "    y2 = np.array([int(y) for y in file.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cZK_CQzBnWZF"
   },
   "outputs": [],
   "source": [
    "def print_scores(y_test, y_pred):\n",
    "    print(\"\\tAccuracy score:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\tF1 score:\", f1_score(y_test, y_pred, average=\"weighted\")) # default is only for binary labels\n",
    "    print(\"\\tMacro F1 score:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"\\tMicro F1 score:\", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(\"\\tMCC:\", matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNqFIh9qnWZF"
   },
   "source": [
    "#### Bayesian classifier\n",
    "\n",
    "TF * IDF weighting done by `TfidfVectorizer()` from sklearn.  \n",
    "Set random_state to keep results the same across mutliple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Uj3mT-mhnWZF"
   },
   "outputs": [],
   "source": [
    "def NB_classifier(X, y):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)\n",
    "    \n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train.toarray(), y_train)\n",
    "    y_pred = classifier.predict(X_test.toarray())\n",
    "    print_scores(y_test, y_pred)\n",
    "    return classifier, X_test.toarray(), y_pred, vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-FZt4LjnWZG",
    "outputId": "779e4ffa-3c72-46b0-d223-676286c850ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1:\n",
      "\tAccuracy score: 0.8434886499402628\n",
      "\tF1 score: 0.8598434552889552\n",
      "\tMacro F1 score: 0.6032082766218806\n",
      "\tMicro F1 score: 0.8434886499402628\n",
      "\tMCC: 0.21998729341226636\n"
     ]
    }
   ],
   "source": [
    "print(\"Task 1:\")\n",
    "NB1_model, NB_X1_test, NB_y1_pred, NB_feature_names1 = NB_classifier(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFNkXac-nWZG",
    "outputId": "1a3c13b5-6f14-4cae-ac7f-5318f8021b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2:\n",
      "\tAccuracy score: 0.8502588610115492\n",
      "\tF1 score: 0.8628120312388717\n",
      "\tMacro F1 score: 0.441313568748656\n",
      "\tMicro F1 score: 0.8502588610115492\n",
      "\tMCC: 0.1966873921225114\n"
     ]
    }
   ],
   "source": [
    "print(\"Task 2:\")\n",
    "NB2_model, NB_X2_test, NB_y2_pred, NB_feature_names2 = NB_classifier(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0AiRRhHnWZG"
   },
   "source": [
    "#### Fasttext text classifier\n",
    "\n",
    "This classifier needs train data to be in file, where each line contains (at least one) label preceeded with `__label__` along with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "peQYEJHEnWZH"
   },
   "outputs": [],
   "source": [
    "def fasttext_classifier(X, y, file_dir=\"\"):\n",
    "    file_path = file_dir + \"merged.txt\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)\n",
    "    \n",
    "    # create file\n",
    "    with open(file_path, \"w\", encoding='utf8') as file:\n",
    "        file.writelines([\"__label__{} {}\".format(y, x) for x, y in zip(X_train, y_train)])\n",
    "    \n",
    "    classifier = fasttext.train_supervised(input=file_path)\n",
    "\n",
    "    y_pred = []\n",
    "    for x, y in zip(X_test, y_test):\n",
    "        pred, _ = classifier.predict(x[:-1])  # remove '\\n'\n",
    "        y_pred.append(int(pred[0][-1]))\n",
    "\n",
    "    print_scores(y_test, y_pred)\n",
    "    return classifier, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfZEDRFMnWZH",
    "outputId": "fbdece7d-2d3d-474f-88e1-2b24bb184478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1:\n",
      "\tAccuracy score: 0.9175627240143369\n",
      "\tF1 score: 0.8866508445337241\n",
      "\tMacro F1 score: 0.5416610451966192\n",
      "\tMicro F1 score: 0.9175627240143369\n",
      "\tMCC: 0.18595918269873282\n"
     ]
    }
   ],
   "source": [
    "print(\"Task 1:\")\n",
    "ft1_model, ft_y1_pred = fasttext_classifier(X1, y1, \"task_6-1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJp2WpIBnWZH",
    "outputId": "efe79918-2ccc-4154-87ad-e01a63afe5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2:\n",
      "\tAccuracy score: 0.9143767423337316\n",
      "\tF1 score: 0.8761932949316045\n",
      "\tMacro F1 score: 0.3386804319748926\n",
      "\tMicro F1 score: 0.9143767423337316\n",
      "\tMCC: 0.05161051748645783\n"
     ]
    }
   ],
   "source": [
    "print(\"Task 2:\")\n",
    "ft2_model, ft_y2_pred = fasttext_classifier(X2, y2, \"task_6-2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8o7d2P1SnWZI"
   },
   "source": [
    "#### Transformer classifier\n",
    "\n",
    "Using ktrain with the help of this: https://towardsdatascience.com/text-classification-with-hugging-face-transformers-in-tensorflow-2-without-tears-ee50e4f3e7ed  \n",
    "Ran on Google Colab.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "14tF6phynWZI"
   },
   "outputs": [],
   "source": [
    "def transformer_classifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)\n",
    "    \n",
    "    model_name = 'bert-base-uncased'\n",
    "    t = ktrain.text.Transformer(model_name, maxlen=500, class_names=list(set(y)))\n",
    "    train_dataset = t.preprocess_train(X_train, y_train)\n",
    "    validation_dataset = t.preprocess_test(X_test, y_test)\n",
    "    model = t.get_classifier()\n",
    "    learner = ktrain.get_learner(model, train_data=train_dataset, val_data=validation_dataset, batch_size=6)\n",
    "    learner.fit_onecycle(5e-5, 4)\n",
    "    \n",
    "    predictor = ktrain.get_predictor(learner.model, preproc=t)\n",
    "    \n",
    "    y_pred = [predictor.predict(x) for x in X_test]\n",
    "    print_scores(y_test, y_pred)\n",
    "    return predictor, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "rNH6dgqHnWZI",
    "outputId": "a5858bd1-c297-46b8-fe59-8c7bfad38c40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1:\n",
      "preprocessing train...\n",
      "language: pl\n",
      "train sequence lengths:\n",
      "\tmean : 12\n",
      "\t95percentile : 21\n",
      "\t99percentile : 24\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: pl\n",
      "test sequence lengths:\n",
      "\tmean : 12\n",
      "\t95percentile : 21\n",
      "\t99percentile : 24\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 5e-05...\n",
      "Epoch 1/4\n",
      "1255/1255 [==============================] - 952s 758ms/step - loss: 0.2950 - accuracy: 0.9125 - val_loss: 0.2824 - val_accuracy: 0.9156\n",
      "Epoch 2/4\n",
      "1255/1255 [==============================] - 952s 759ms/step - loss: 0.2910 - accuracy: 0.9151 - val_loss: 0.2938 - val_accuracy: 0.9156\n",
      "Epoch 3/4\n",
      "1255/1255 [==============================] - 949s 756ms/step - loss: 0.2934 - accuracy: 0.9151 - val_loss: 0.2911 - val_accuracy: 0.9156\n",
      "Epoch 4/4\n",
      "1255/1255 [==============================] - 949s 756ms/step - loss: 0.2953 - accuracy: 0.9151 - val_loss: 0.2895 - val_accuracy: 0.9156\n",
      "\tAccuracy score: 0.9155714854639586\n",
      "\tF1 score: 0.8752178150027612\n",
      "\tMacro F1 score: 0.47796257796257796\n",
      "\tMicro F1 score: 0.9155714854639586\n",
      "\tMCC: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "print(\"Task 1:\")\n",
    "t1_model, t_y1_pred = transformer_classifier(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "3zF-Oa9xnWZI",
    "outputId": "4cba61af-e560-4a9f-9fdb-3103327f86f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2:\n",
      "preprocessing train...\n",
      "language: pl\n",
      "train sequence lengths:\n",
      "\tmean : 12\n",
      "\t95percentile : 21\n",
      "\t99percentile : 24\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: pl\n",
      "test sequence lengths:\n",
      "\tmean : 12\n",
      "\t95percentile : 21\n",
      "\t99percentile : 24\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 5e-05...\n",
      "Epoch 1/4\n",
      "1255/1255 [==============================] - 955s 761ms/step - loss: 0.3571 - accuracy: 0.9135 - val_loss: 0.3487 - val_accuracy: 0.9156\n",
      "Epoch 2/4\n",
      "1255/1255 [==============================] - 952s 759ms/step - loss: 0.3409 - accuracy: 0.9151 - val_loss: 0.3499 - val_accuracy: 0.9156\n",
      "Epoch 3/4\n",
      "1255/1255 [==============================] - 951s 758ms/step - loss: 0.3478 - accuracy: 0.9153 - val_loss: 0.3397 - val_accuracy: 0.9156\n",
      "Epoch 4/4\n",
      "1255/1255 [==============================] - 950s 757ms/step - loss: 0.3462 - accuracy: 0.9151 - val_loss: 0.3395 - val_accuracy: 0.9156\n",
      "\tAccuracy score: 0.9155714854639586\n",
      "\tF1 score: 0.8752178150027612\n",
      "\tMacro F1 score: 0.31864171864171864\n",
      "\tMicro F1 score: 0.9155714854639586\n",
      "\tMCC: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "print(\"Task 2:\")\n",
    "t2_model, t_y2_pred = transformer_classifier(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEZBQqgKyPyl"
   },
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WR5fTpWO07UB"
   },
   "outputs": [],
   "source": [
    "_, X_test, _, y_test = train_test_split(X1, y1, random_state=7)  # same split as in classifiers\n",
    "\n",
    "tp, fp, tn, fn = None, None, None, None\n",
    "for i in range(len(X_test)):\n",
    "    if y_test[i] == ft_y1_pred[i] == 1:\n",
    "        tp = (i, str(X_test[i])[:-1])\n",
    "        # print(tp)\n",
    "        break\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    if y_test[i] == ft_y1_pred[i] == 0:\n",
    "        tn = (i, str(X_test[i])[:-1])\n",
    "        # print(tn)\n",
    "        break\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    if y_test[i] != ft_y1_pred[i] and ft_y1_pred[i] == 1:\n",
    "        fp = (i, str(X_test[i])[:-1])\n",
    "        # print(fp)\n",
    "        break\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    if y_test[i] != ft_y1_pred[i] and ft_y1_pred[i] == 0:\n",
    "        fn = (i, str(X_test[i])[:-1])\n",
    "        # print(fn)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4ae3cf261a424ce3918c8ef616bab7b8",
      "f2542c28aa854614ba3d9d468e8b78a6",
      "bf3b5141fe7643c091d31763ae107a3c",
      "8877eacbc8474a5aaa525b1db87912f7",
      "bf1568c788cb4ff0b12919be312be27c",
      "576bad94c0c74e6c99b9d5e624190cf1",
      "4ae2dafee23d4e8aa9913b7f643bc30f",
      "b2fa43e6a2e94439bce2fbc6dec547e7"
     ]
    },
    "id": "TOlEHewJAHDt",
    "outputId": "ad3c99b9-5f56-447d-a8f0-e9fb827dbdf7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae3cf261a424ce3918c8ef616bab7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NG_values = np.array([NB_X1_test[i] for i in [tp[0], tn[0], fp[0], fn[0]]])\n",
    "# explainer = shap.KernelExplainer(NB1_model.predict, shap.kmeans(NB_X1_test, 10)) # this used up all RAM and blew up Colab\n",
    "# # shap.initjs()\n",
    "# shap_values = explainer.shap_values(NG_values)\n",
    "# shap.force_plot(explainer.expected_value, shap_values, feature_names=NB_feature_names, matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHSW4cTOlYGq"
   },
   "outputs": [],
   "source": [
    "# this fails because predict() in this model expects a single sample\n",
    "# explainer = shap.KernelExplainer(ft1_model.predict, [tp[1], tn[1], fp[1], fn[1]])\n",
    "# shap_values = explainer.shap_values([tp[1], tn[1], fp[1], fn[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAJpsYNF07z4"
   },
   "source": [
    "### Task 5\n",
    "#### Which of the classifiers works the best for the task 1 and the task 2.\n",
    "In the first case fasttext worked the best, but transformer was the close second.  \n",
    "The second task I'd call a draw between fasttext and transformer.  \n",
    "**It is worth to note that these results are for only one possible split of data.**\n",
    "#### Did you achieve results comparable with the results of PolEval Task?\n",
    "For task 6.1 somehow better(?) results here.  \n",
    "For task 6.2 comparable micro F1-score and way worse macro F1-score.\n",
    "#### Did you achieve results comparabie with the Klej leaderboard?\n",
    "Here results are comparable only when looking at Average, for the CBD the results are better.  \n",
    "I think this and previous point proves that a single split on a single dataset does not yield reliable results. (I don't believe that this simple model has just beaten the competition)\n",
    "#### Describe strengths and weaknesses of each of the compared algorithms.\n",
    "Bayesian classifier is the simplest of three, both in case of logic and implementation. The other downside is that it assumes that all features are totally unrelated to each other.  \n",
    "Fasttext has for sure the weirdest implementation and is difficult to use (enforcing samples with labels in the single line in FILE or predict() throwing an error when it finds more than one sample to predict at a time). Nevertheless it \"won\" between this three models (with possibly very biased train-test data split but still, all of the models had the same split).  \n",
    "Transformer is the most sophisticated one and might prove to be the best with correct parameters (learning_rate, number of epochs). The big downside is that it is VERY slow, trying to run it on my computer would need a whole day, even the Colab with GPU support needed over and hour for one model.\n",
    "#### Do you think comparison of raw performance values on a single task is enough to assess the value of a given algorithm/model?\n",
    "It is not enough since the a single dataset might not contain e.g. some words that are strongly positive or negative and model would have problem with even a simple sample (2-3 words) if it contained such words.  \n",
    "Also, we face the risk of overfitting the model, so it will one work nice for this particular data and not any other.\n",
    "#### Did SHAP show that the models use valuable features/words when performing their decision?\n",
    "SHAP when given only 4 values returned nonsense and when I tried to feed more data (raw or using kmeans()) even the Colab refused to handle it and restarted (clearing\n",
    " the environment).  \n",
    "Also Colab likes to 'detach' you suddenly from the environment without a warning which didn't help in trying to get it to work.  \n",
    "I couldn't figure out how to run SHAP for other two models (e.g. fasttext's predict() works for single samples and using Explainer on it throws an error)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab8.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4ae2dafee23d4e8aa9913b7f643bc30f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ae3cf261a424ce3918c8ef616bab7b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf3b5141fe7643c091d31763ae107a3c",
       "IPY_MODEL_8877eacbc8474a5aaa525b1db87912f7"
      ],
      "layout": "IPY_MODEL_f2542c28aa854614ba3d9d468e8b78a6"
     }
    },
    "576bad94c0c74e6c99b9d5e624190cf1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8877eacbc8474a5aaa525b1db87912f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2fa43e6a2e94439bce2fbc6dec547e7",
      "placeholder": "​",
      "style": "IPY_MODEL_4ae2dafee23d4e8aa9913b7f643bc30f",
      "value": " 0/4 [00:00&lt;?, ?it/s]"
     }
    },
    "b2fa43e6a2e94439bce2fbc6dec547e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf1568c788cb4ff0b12919be312be27c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bf3b5141fe7643c091d31763ae107a3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_576bad94c0c74e6c99b9d5e624190cf1",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf1568c788cb4ff0b12919be312be27c",
      "value": 0
     }
    },
    "f2542c28aa854614ba3d9d468e8b78a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}