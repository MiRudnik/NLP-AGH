{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Getting top 3 models from: https://huggingface.co/models?filter=pl (skipping dkleczek/bert-base-polish-uncased-v1 since cased version is stated as an upgrade to this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-cased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model1 = {\"name\": \"dkleczek/bert-base-polish-cased-v1\",\n",
    "         \"tokenizer\": BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\"),\n",
    "         \"model\": BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertForMaskedLM: ['cls.sso.sso_relationship.weight', 'cls.sso.sso_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model2 = {\"name\": \"allegro/herbert-base-cased\",\n",
    "         \"tokenizer\": AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\"),\n",
    "         \"model\": BertForMaskedLM.from_pretrained(\"allegro/herbert-base-cased\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-large-cased were not used when initializing BertForMaskedLM: ['cls.sso.sso_relationship.weight', 'cls.sso.sso_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model3 = {\"name\": \"allegro/herbert-large-cased\",\n",
    "         \"tokenizer\": AutoTokenizer.from_pretrained(\"allegro/herbert-large-cased\"),\n",
    "         \"model\": BertForMaskedLM.from_pretrained(\"allegro/herbert-large-cased\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sentence(sentence, model, tokenizer, num_predictions=5):\n",
    "    sentence = sentence.replace(\"[MASK]\", tokenizer.mask_token)\n",
    "    sentence_encoded = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(sentence_encoded == tokenizer.mask_token_id)[1][0].item()\n",
    "    token_logits = model(sentence_encoded)[0]\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    top_tokens = torch.topk(mask_token_logits, num_predictions)[-1]\n",
    "    for token in top_tokens:\n",
    "        print(\"\\t{}\".format(sentence.replace(tokenizer.mask_token, tokenizer.decode([token]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Warszawa to największe [MASK].\",\n",
    "             \"Te zabawki należą do [MASK].\",\n",
    "             \"Policjant przygląda się [MASK].\",\n",
    "             \"Na środku skrzyżowania widać [MASK].\",\n",
    "             \"Właściciel samochodu widział złodzieja z [MASK].\",\n",
    "             \"Prezydent z premierem rozmawiali wczoraj o [MASK].\",\n",
    "             \"Witaj drogi [MASK].\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Warszawa to największe [MASK].:\n",
      "\tWarszawa to największe miasto.\n",
      "\tWarszawa to największe województwo.\n",
      "\tWarszawa to największe lotnisko.\n",
      "\tWarszawa to największe miasteczko.\n",
      "\tWarszawa to największe państwo.\n",
      "Te zabawki należą do [MASK].:\n",
      "\tTe zabawki należą do ciebie.\n",
      "\tTe zabawki należą do mnie.\n",
      "\tTe zabawki należą do nas.\n",
      "\tTe zabawki należą do pana.\n",
      "\tTe zabawki należą do niego.\n",
      "Policjant przygląda się [MASK].:\n",
      "\tPolicjant przygląda się temu.\n",
      "\tPolicjant przygląda się sprawie.\n",
      "\tPolicjant przygląda się im.\n",
      "\tPolicjant przygląda się wszystkiemu.\n",
      "\tPolicjant przygląda się panu.\n",
      "Na środku skrzyżowania widać [MASK].:\n",
      "\tNa środku skrzyżowania widać rzekę.\n",
      "\tNa środku skrzyżowania widać ulicę.\n",
      "\tNa środku skrzyżowania widać drzewa.\n",
      "\tNa środku skrzyżowania widać drogę.\n",
      "\tNa środku skrzyżowania widać las.\n",
      "Właściciel samochodu widział złodzieja z [MASK].:\n",
      "\tWłaściciel samochodu widział złodzieja z bronią.\n",
      "\tWłaściciel samochodu widział złodzieja z tyłu.\n",
      "\tWłaściciel samochodu widział złodzieja z ulicy.\n",
      "\tWłaściciel samochodu widział złodzieja z bliska.\n",
      "\tWłaściciel samochodu widział złodzieja z zewnątrz.\n",
      "Prezydent z premierem rozmawiali wczoraj o [MASK].:\n",
      "\tPrezydent z premierem rozmawiali wczoraj o tym.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o Polsce.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o budżecie.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o ASF.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o ustawie.\n",
      "Witaj drogi [MASK].:\n",
      "\tWitaj drogi chłopcze.\n",
      "\tWitaj drogi przyjacielu.\n",
      "\tWitaj drogi bracie.\n",
      "\tWitaj drogi kolego.\n",
      "\tWitaj drogi synu.\n",
      "\n",
      "allegro/herbert-base-cased\n",
      "Warszawa to największe [MASK].:\n",
      "\tWarszawa to największe miasto.\n",
      "\tWarszawa to największe lotnisko.\n",
      "\tWarszawa to największe centrum.\n",
      "\tWarszawa to największe miasta.\n",
      "\tWarszawa to największe atrakcje.\n",
      "Te zabawki należą do [MASK].:\n",
      "\tTe zabawki należą do rodziny.\n",
      "\tTe zabawki należą do nas.\n",
      "\tTe zabawki należą do nich.\n",
      "\tTe zabawki należą do najlepszych.\n",
      "\tTe zabawki należą do ..\n",
      "Policjant przygląda się [MASK].:\n",
      "\tPolicjant przygląda się mężczyźnie.\n",
      "\tPolicjant przygląda się kobiecie.\n",
      "\tPolicjant przygląda się mu.\n",
      "\tPolicjant przygląda się dziewczynie.\n",
      "\tPolicjant przygląda się sprawie.\n",
      "Na środku skrzyżowania widać [MASK].:\n",
      "\tNa środku skrzyżowania widać rondo.\n",
      "\tNa środku skrzyżowania widać samochody.\n",
      "\tNa środku skrzyżowania widać radiowóz.\n",
      "\tNa środku skrzyżowania widać samochód.\n",
      "\tNa środku skrzyżowania widać wiadukt.\n",
      "Właściciel samochodu widział złodzieja z [MASK].:\n",
      "\tWłaściciel samochodu widział złodzieja z samochodu.\n",
      "\tWłaściciel samochodu widział złodzieja z włamaniem.\n",
      "\tWłaściciel samochodu widział złodzieja z auta.\n",
      "\tWłaściciel samochodu widział złodzieja z kierowcą.\n",
      "\tWłaściciel samochodu widział złodzieja z parkingu.\n",
      "Prezydent z premierem rozmawiali wczoraj o [MASK].:\n",
      "\tPrezydent z premierem rozmawiali wczoraj o przyszłości.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o Polsce.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o bezpieczeństwie.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o polityce.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o Warszawie.\n",
      "Witaj drogi [MASK].:\n",
      "\tWitaj drogi Łukasz.\n",
      "\tWitaj drogi Boże.\n",
      "\tWitaj drogi człowieku.\n",
      "\tWitaj drogi Karol.\n",
      "\tWitaj drogi Marcin.\n",
      "\n",
      "allegro/herbert-large-cased\n",
      "Warszawa to największe [MASK].:\n",
      "\tWarszawa to największe miasto.\n",
      "\tWarszawa to największe miasta.\n",
      "\tWarszawa to największe ..\n",
      "\tWarszawa to największe lotnisko.\n",
      "\tWarszawa to największe miast.\n",
      "Te zabawki należą do [MASK].:\n",
      "\tTe zabawki należą do dzieci.\n",
      "\tTe zabawki należą do mnie.\n",
      "\tTe zabawki należą do nas.\n",
      "\tTe zabawki należą do najmłodszych.\n",
      "\tTe zabawki należą do Ciebie.\n",
      "Policjant przygląda się [MASK].:\n",
      "\tPolicjant przygląda się sprawie.\n",
      "\tPolicjant przygląda się sytuacji.\n",
      "\tPolicjant przygląda się zdarzeniu.\n",
      "\tPolicjant przygląda się wszystkiemu.\n",
      "\tPolicjant przygląda się kobiecie.\n",
      "Na środku skrzyżowania widać [MASK].:\n",
      "\tNa środku skrzyżowania widać rondo.\n",
      "\tNa środku skrzyżowania widać krzyż.\n",
      "\tNa środku skrzyżowania widać radiowóz.\n",
      "\tNa środku skrzyżowania widać samochód.\n",
      "\tNa środku skrzyżowania widać znak.\n",
      "Właściciel samochodu widział złodzieja z [MASK].:\n",
      "\tWłaściciel samochodu widział złodzieja z bronią.\n",
      "\tWłaściciel samochodu widział złodzieja z bliska.\n",
      "\tWłaściciel samochodu widział złodzieja z kamerą.\n",
      "\tWłaściciel samochodu widział złodzieja z nożem.\n",
      "\tWłaściciel samochodu widział złodzieja z kamery.\n",
      "Prezydent z premierem rozmawiali wczoraj o [MASK].:\n",
      "\tPrezydent z premierem rozmawiali wczoraj o tym.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o sprawie.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o sytuacji.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o prywatyzacji.\n",
      "\tPrezydent z premierem rozmawiali wczoraj o ..\n",
      "Witaj drogi [MASK].:\n",
      "\tWitaj drogi człowieku.\n",
      "\tWitaj drogi Panie.\n",
      "\tWitaj drogi Jezu.\n",
      "\tWitaj drogi panie.\n",
      "\tWitaj drogi misiu.\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print()\n",
    "    print(model[\"name\"])\n",
    "    for s in sentences:\n",
    "        print(\"{}:\".format(s))\n",
    "        fill_sentence(s, model[\"model\"], model[\"tokenizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie [MASK].\",\n",
    "             \"Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie [MASK].\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie [MASK].:\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zgodził.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie dowiedział.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie martwił.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie bał.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zabił.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie [MASK].:\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zgodziła.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie bała.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie dowiedziała.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zabiła.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie pojawiła.\n",
      "\n",
      "allegro/herbert-base-cased\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie [MASK].:\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zdziwił.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie poddał.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie dowiedział.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zastanawiał.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie przyznał.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie [MASK].:\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie dowiedziała.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie przyznała.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie bała.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie śmiała.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zmieniła.\n",
      "\n",
      "allegro/herbert-large-cased\n",
      "Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie [MASK].:\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie bał.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie poddał.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zabił.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie śmiał.\n",
      "\tGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zastanawiał.\n",
      "Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie [MASK].:\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie bała.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zgodziła.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie dowiedziała.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zmieniła.\n",
      "\tGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie śmiała.\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print()\n",
    "    print(model[\"name\"])\n",
    "    for s in sentences:\n",
    "        print(\"{}:\".format(s))\n",
    "        fill_sentence(s, model[\"model\"], model[\"tokenizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\",\n",
    "             \"W wakacje odwiedziłem [MASK], który jest stolicą Islandii.\",\n",
    "             \"Informatyka na [MASK] należy do najlepszych kierunków w Polsce.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.:\n",
      "\tWoda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tMięso wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tSłońce wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tNie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tPiwo wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "W wakacje odwiedziłem [MASK], który jest stolicą Islandii.:\n",
      "\tW wakacje odwiedziłem kraj, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Cypr, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Meksyk, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Gibraltar, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Wellington, który jest stolicą Islandii.\n",
      "Informatyka na [MASK] należy do najlepszych kierunków w Polsce.:\n",
      "\tInformatyka na wsi należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na świecie należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na żywo należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na pewno należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na odległość należy do najlepszych kierunków w Polsce.\n",
      "\n",
      "allegro/herbert-base-cased\n",
      "[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.:\n",
      "\tWoda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tSłońce wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tZiemia wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tNastępnie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tCiało wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "W wakacje odwiedziłem [MASK], który jest stolicą Islandii.:\n",
      "\tW wakacje odwiedziłem Kraków, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Oslo, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Londyn, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Gdańsk, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Toruń, który jest stolicą Islandii.\n",
      "Informatyka na [MASK] należy do najlepszych kierunków w Polsce.:\n",
      "\tInformatyka na pewno należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na AGH należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na UW należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na studiach należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na UMK należy do najlepszych kierunków w Polsce.\n",
      "\n",
      "allegro/herbert-large-cased\n",
      "[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.:\n",
      "\tWoda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tKrew wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\twoda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tOgień wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "\tNie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\n",
      "W wakacje odwiedziłem [MASK], który jest stolicą Islandii.:\n",
      "\tW wakacje odwiedziłem Oslo, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Londyn, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Liverpool, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Glasgow, który jest stolicą Islandii.\n",
      "\tW wakacje odwiedziłem Birmingham, który jest stolicą Islandii.\n",
      "Informatyka na [MASK] należy do najlepszych kierunków w Polsce.:\n",
      "\tInformatyka na AGH należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na UW należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na UJ należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na UAM należy do najlepszych kierunków w Polsce.\n",
      "\tInformatyka na uczelni należy do najlepszych kierunków w Polsce.\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print()\n",
    "    print(model[\"name\"])\n",
    "    for s in sentences:\n",
    "        print(\"{}:\".format(s))\n",
    "        fill_sentence(s, model[\"model\"], model[\"tokenizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "#### Which of the models produced the best results?\n",
    "I would say that depending on the sentence different models came out on top. If I had to position them from worst to best then:  \n",
    "\n",
    "3\\. dkleczek/bert-base-polish-cased-v1 - the only one with correct Vocative but in the last two sentences it totally missed  \n",
    "2\\. allegro/herbert-base-cased - in `W wakacje odwiedziłem ...` first result is much better than in dkleczek's model (country as a capital?)  \n",
    "1\\. allegro/herbert-large-cased - better first result in the last sentence (not only in chosen University but also the context :P) and more human-like first result in `Gdybym wiedział(a) wtedy ...` (base-cased propositions are \"correct\" but seem very artificial: `Gdybym wiedziała to bym się nie dowiedziała.`)  \n",
    "\n",
    "But it is worth noting that dkleczek's model always returned some word, whereas the rest sometimes returned `.` which would be a dead giveaway if it happened while imitating a real person.\n",
    "#### Was any of the models able to capture Polish grammar?\n",
    "All the models correctly handled grammatical genders (sentences: `Gdybym wiedział(a) wtedy...`).  \n",
    "Considering grammatical cases allegro models (especially herbert-base-cased) had some difficulties with the last one - Vocative: `Witaj drogi ...` (I think its use is diminishing in polish language, at least in speech, so maybe that's these errors happened).\n",
    "#### Was any of the models able to capture long-distant relationships between the words?\n",
    "Yes, allegro models in sentence `Informatyka na ... należy` returned names of universities or words that had some sense in a sentence (\"uczelni\", \"pewno\"). \n",
    "#### Was any of the models able to capture world knowledge?\n",
    "Yes, all the models returned that water boils in 100 degrees and freezes in 0 (next predictions are a bit weird as a whole sentence but here I expected one obvious answer).  \n",
    "The first model got lost in the sentence about Computer Science, but the rest were okay.  \n",
    "But ALL of them couldn't handle `W wakacje odwiedziłem ...`.\n",
    "#### What are the most striking errors made by the models?\n",
    "- Problem with the last grammatical case (looking at the first ones I didn't expect any problems further)\n",
    "- Poor knowledge of geography? At first I thought that maybe `W wakacje odwiedziłem ..., który jest stolicą Islandii.` was too complex and models focused on the first part of the sentence, not taking into account the dependency later. But I checked it below and it turns out that it does know some capitals, but only the easiest ones and Iceland unfortunately didn't fall into this category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dkleczek/bert-base-polish-cased-v1\n",
      "[MASK] jest stolicą Islandii.:\n",
      "\tMiasto jest stolicą Islandii.\n",
      "\tOslo jest stolicą Islandii.\n",
      "\tNorwegia jest stolicą Islandii.\n",
      "[MASK] jest stolicą Francji.:\n",
      "\tParyż jest stolicą Francji.\n",
      "\tBruksela jest stolicą Francji.\n",
      "\tLyon jest stolicą Francji.\n",
      "[MASK] jest stolicą Niemiec.:\n",
      "\tBerlin jest stolicą Niemiec.\n",
      "\tHamburg jest stolicą Niemiec.\n",
      "\tFrankfurt jest stolicą Niemiec.\n",
      "[MASK] jest stolicą Wielkiej Brytanii.:\n",
      "\tLondyn jest stolicą Wielkiej Brytanii.\n",
      "\tBirmingham jest stolicą Wielkiej Brytanii.\n",
      "\tGlasgow jest stolicą Wielkiej Brytanii.\n",
      "[MASK] jest stolicą Serbii.:\n",
      "\tSerbia jest stolicą Serbii.\n",
      "\tMiasto jest stolicą Serbii.\n",
      "\tObecnie jest stolicą Serbii.\n",
      "[MASK] jest stolicą Wenezueli.:\n",
      "\tObecnie jest stolicą Wenezueli.\n",
      "\tMiasto jest stolicą Wenezueli.\n",
      "\tKolumbia jest stolicą Wenezueli.\n",
      "\n",
      "allegro/herbert-base-cased\n",
      "[MASK] jest stolicą Islandii.:\n",
      "\tMiasto jest stolicą Islandii.\n",
      "\tOslo jest stolicą Islandii.\n",
      "\tMiejscowość jest stolicą Islandii.\n",
      "[MASK] jest stolicą Francji.:\n",
      "\tParyż jest stolicą Francji.\n",
      "\tLyon jest stolicą Francji.\n",
      "\tFrancja jest stolicą Francji.\n",
      "[MASK] jest stolicą Niemiec.:\n",
      "\tBerlin jest stolicą Niemiec.\n",
      "\tStuttgart jest stolicą Niemiec.\n",
      "\tWiedeń jest stolicą Niemiec.\n",
      "[MASK] jest stolicą Wielkiej Brytanii.:\n",
      "\tLondyn jest stolicą Wielkiej Brytanii.\n",
      "\tManchester jest stolicą Wielkiej Brytanii.\n",
      "\tGlasgow jest stolicą Wielkiej Brytanii.\n",
      "[MASK] jest stolicą Serbii.:\n",
      "\tMiasto jest stolicą Serbii.\n",
      "\tObecnie jest stolicą Serbii.\n",
      "\tChorwacja jest stolicą Serbii.\n",
      "[MASK] jest stolicą Wenezueli.:\n",
      "\tMiasto jest stolicą Wenezueli.\n",
      "\tMadryt jest stolicą Wenezueli.\n",
      "\tDziś jest stolicą Wenezueli.\n",
      "\n",
      "allegro/herbert-large-cased\n",
      "[MASK] jest stolicą Islandii.:\n",
      "\tOslo jest stolicą Islandii.\n",
      "\tMiasto jest stolicą Islandii.\n",
      "\tStolica jest stolicą Islandii.\n",
      "[MASK] jest stolicą Francji.:\n",
      "\tParyż jest stolicą Francji.\n",
      "\tLyon jest stolicą Francji.\n",
      "\tFrancja jest stolicą Francji.\n",
      "[MASK] jest stolicą Niemiec.:\n",
      "\tBerlin jest stolicą Niemiec.\n",
      "\tMonachium jest stolicą Niemiec.\n",
      "\tKolonia jest stolicą Niemiec.\n",
      "[MASK] jest stolicą Wielkiej Brytanii.:\n",
      "\tLondyn jest stolicą Wielkiej Brytanii.\n",
      "\tStolica jest stolicą Wielkiej Brytanii.\n",
      "\tLondon jest stolicą Wielkiej Brytanii.\n",
      "[MASK] jest stolicą Serbii.:\n",
      "\tStolica jest stolicą Serbii.\n",
      "\tObecnie jest stolicą Serbii.\n",
      "\tMiasto jest stolicą Serbii.\n",
      "[MASK] jest stolicą Wenezueli.:\n",
      "\tMiasto jest stolicą Wenezueli.\n",
      "\tStolica jest stolicą Wenezueli.\n",
      "\tObecnie jest stolicą Wenezueli.\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"[MASK] jest stolicą Islandii.\",\n",
    "             \"[MASK] jest stolicą Francji.\",\n",
    "             \"[MASK] jest stolicą Niemiec.\",\n",
    "             \"[MASK] jest stolicą Wielkiej Brytanii.\",\n",
    "             \"[MASK] jest stolicą Serbii.\",\n",
    "             \"[MASK] jest stolicą Wenezueli.\"]\n",
    "\n",
    "for model in models:\n",
    "    print()\n",
    "    print(model[\"name\"])\n",
    "    for s in sentences:\n",
    "        print(\"{}:\".format(s))\n",
    "        fill_sentence(s, model[\"model\"], model[\"tokenizer\"], 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
